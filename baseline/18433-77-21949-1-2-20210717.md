                              Proceedings of the Tenth International Symposium on Combinatorial Search (SoCS 2017)




     An Analysis and Enhancement of the Gap Heuristic for the Pancake Puzzle

                          Richard Valenzano                                              Danniel Sihui Yang
                     Department of Computer Science                                Department of Computer Science
                          University of Toronto                                         University of Toronto
                        Toronto, Ontario, Canada                                      Toronto, Ontario, Canada
                       rvalenzano@cs.toronto.edu                                    dannielyang1996@gmail.com



                            Abstract                                        plicity, and that it has a higher branching factor than other
                                                                            standard domains like the sliding tile puzzle.
  The pancake puzzle is a standard benchmark domain used                       The heuristic function most often used in such work is the
  to test search algorithms, and the gap heuristic is the state-
  of-the-art heuristic function most often used in such tests.
                                                                            gap heuristic (Helmert 2010), which is generally viewed as
  In this work, we analyze the accuracy of this heuristic and               being very accurate. In this paper, we analyze this heuristic
  identify ways to enhance it. We begin by showing that in the              in an effort to increase our understanding of its properties
  worst-case, the amount that the gap heuristic underestimates              and thereby better equip researchers who are using the pan-
  the optimal cost of a pancake puzzle state can be linear in the           cake puzzle to evaluate a search algorithm. Our empirical
  number of pancakes in the stack. However, empirical analysis              analysis shows that the gap heuristic is accurate on a very
  suggests that it is extremely rare that the gap heuristic under-          high percentage of states, and rarely underestimates the op-
  estimates the optimal cost by more than two. We then iden-                timal cost of a randomly generated state by more than two.
  tify several simple methods that can be used to generate large            However, the gap heuristic can be much more inaccurate,
  sets of problems on which the gap heuristic underestimates                which we show by using existing results on the diameter of
  the optimal cost by a larger amount than it typically does on
  random permutations. In doing so, we provide new pancake
                                                                            the pancake puzzle to prove that the worst-case heuristic er-
  puzzle test sets that can be used to evaluate how search algo-            ror of any state with N pancakes grows linearly with N .
  rithms behave when the heuristic is inaccurate.                           We then deﬁne several methods for generating large sets of
  We also formally characterize states according to the size                states with a higher average heuristic error than random per-
  of the heuristic plateaus around them. This characterization              mutations. In doing so, we have provided new benchmarks
  allows us to efﬁciently compute a two-step lookahead of                   that can be used to evaluate search algorithms on problems
  the gap heuristic on any state, which we can use alongside                with a high branching factor on which the heuristic is not
  a state’s dual to further improve heuristic accuracy. These               almost always providing nearly perfect estimates.
  enhancements substantially improve the performance of an                     We have also formally studied the local search topology of
  IDA∗ -based pancake problem solver on both the existing                   the gap heuristic. In particular, we classify states according
  benchmarks and the new ones proposed in this paper.                       to their distance from the nearest state with a lower heuristic
                                                                            value and show that there are no heuristic local minima. We
                     1     Introduction                                     then identify that the topology of the gap heuristic allows us
                                                                            to efﬁciently compute the value of a one or two step looka-
The pancake puzzle (Gates and Papadimitriou 1979) is a                      head from every state, and thereby improve the admissible
classic combinatorial problem that is related to a number of                heuristic estimates being used by the search. This efﬁcient
applications, including routing in a parallel computer (Qiu,                lookahead can be combined with methods for exploiting a
Meijer, and Akl 1991) and the calculation of genome simi-                   state’s dual, and the resulting enhancements are shown to
larity (Hayes 2007). In this problem, a chef must sort a stack              substantially decrease search time when used on both the
of pancakes in increasing size from top to bottom, given a                  existing and new benchmark problems.
spatula that can be used to ﬂip some portion of the top of
the stack, using as few ﬂips as possible. The pancake puz-
zle has been extensively studied by the algorithms commu-
                                                                                                  2     Background
nity (Gates and Papadimitriou 1979; Heydari and Sudbor-                     In this section, we provide background on the pancake prob-
ough 1997; Chitturi et al. 2009; Fischer and Ginzinger 2005;                lem and deﬁne the notation used in the rest of the paper.
Bulteau, Fertin, and Rusu 2015), and has become a stan-
dard benchmark for comparing and analyzing search al-                       Sequences and Permutations. We represent a sequence
gorithms (Bouzy 2015; Lippi, Ernandes, and Felner 2016;                     σ of k elements from some set as σ = e1 , ..., ek . We use
Zahavi et al. 2008). This is due in part to the problem’s sim-              σ[i] to refer to the i-th element of σ (i.e. σ[i] = ei ). No-
                                                                            tice that the ﬁrst element in the permutation is at location
Copyright  c 2017, Association for the Advancement of Artiﬁcial            1, which is the convention in the pancake puzzle literature.
Intelligence (www.aaai.org). All rights reserved.                           If σ  = g1 , ..., gk  is a second sequence, then σ ◦ σ  de-



                                                                      109
notes the concatenation of these sequences. This means that                  IDA∗ (Korf 1985) is an algorithm which iteratively per-
σ ◦ σ  = e1 , ..., ek , g1 , ..., gk .                                forms a sequence of threshold-limited depth-ﬁrst searches.
   A permutation π of size N is a sequence of the natural                 Given heuristic h, the initial threshold is set as h(πinit ). Dur-
numbers from 1 to N , such that each element in the sequence              ing each iteration, node n is pruned if its f -cost, deﬁned as
is unique. The dual or inverse of a permutation π, is deﬁned              f (n) = g(n) + h(n.state), is larger than the current thresh-
as the permutation π D where for every 1 ≤ i, j ≤ N , if                  old. The threshold for iteration i + 1 is set as the minimum
π[i] = j then π D [j] = i. For example, 3, 1, 2 is the dual             f -cost of all nodes pruned during iteration i. IDA∗ is guar-
of 2, 3, 1. Intuitively, π[i] refers to the natural number at           anteed to return optimal solutions if h is admissible.
location i of π, and π D [j] refers to the location of j in π.            The Gap Heuristic. We deﬁne the gap heuristic (Helmert
The Pancake Puzzle. An N -pancake puzzle state is a                       2010), which we denote by hG , using the extended permu-
stack of N different sized pancakes, which is represented by              tation π e of π. Permutation π e is deﬁned as π ◦ N + 1. The
a permutation of size N . The natural number i in this per-               value N +1 can be thought of as the plate below the pancake
mutation refers to the i-th smallest pancake, and the order of            stack, though we often refer to it as the N + 1-st pancake.
the numbers in the permutation corresponds to the order of                Moreover, due to the one-to-one correspondence between π
the pancakes in the stack from top to bottom. For example,                and π e we often refer to π[N + 1], the “N + 1-st pancake”
2, 1, 4, 3 represents a 4-pancake state in which the second             of π, or “location N + 1” in π.
smallest pancake is at the top of the stack.                                 For any j where 1 ≤ j ≤ N , an adjacency is said to occur
                                                                          in π e between locations j and j + 1, or between pancakes
   In any N -pancake state π, there are N − 1 applicable
                                                                          π e [j] and π e [j + 1], if |π e [j] − π e [j + 1]| = 1. A gap is said
actions or moves, given by M2 , M3 , ..., MN , and we use
                                                                          to occur between those locations (or those pancakes) if an
Mi (π) to denote the permutation that is the result of ap-
                                                                          adjacency does not occur. The value of hG (π) is then given
plying action Mi to π. Each action Mi reverses the order
                                                                          by the count of the number of gaps in π e :
of the ﬁrst i values in the stack. Formally, this means that
Mi (π)[j] = π[i−j+1] for every j ≤ i, and Mi (π)[j] = π[j]                   hG (π) = |{j | 1 ≤ j ≤ N, |π e [j] − π e [j + 1]| > 1}|
for every j > i. For example, M3 (2, 1, 4, 3) = 4, 1, 2, 3.           Since any action can only add or remove at most one gap and
Deﬁnition 1. Given N -pancake state πinit , the N -pancake                there are no gaps in πgoal , hG is admissible and consistent.
puzzle task is to ﬁnd the shortest or optimal sequence of                    If action Mi removes a gap when applied to state π (i.e.
actions that transforms πinit into state πgoal = 1, 2, ..., N .         hG (Mi (π)) = hG (π) − 1), then Mi is called a gap decreas-
                                                                          ing move in π. Similarly, Mi is a gap increasing move if it
   The N -pancake puzzle task has been shown to be NP-hard                introduces a gap, while if it replaces one gap with another or
(Bulteau, Fertin, and Rusu 2015). For any N , the diameter                one adjacency with another, Mi is a gap neutral move.
of the N -pancake puzzle — deﬁned as the longest optimal                     We note that action Mi will move π[1] on top of π[i + 1],
solution to any N -pancake state — is known to be at least                and so determining if Mi is a gap decreasing, increasing, or
 15
  14 · N  (Heydari and Sudborough 1997) and no more than                 neutral move merely involves checking if |π[1] − π[i + 1]| =
 18
  11 · N  (Chitturi et al. 2009). A 2-approximation algorithm            1, and if there is a gap between pancakes π[i] and π[i + 1].
has also been given by Fischer and Ginzinger (2005).                      This allows for a constant time computation of the difference
                                                                          between hG (Mi (π)) and hG (π). Given π and hG (π), we
State-Space Search, Heuristics, and IDA∗ . From the                       can therefore efﬁciently calculate hG (Mi (π)) without gen-
perspective of state-space search, the pancake puzzle task                erating Mi (π). This incremental computation of hG , which
involves ﬁnding the lowest cost solution from state πinit to              we use in our experiments, is a well-known optimization that
state πgoal in a unit-cost state-space with N ! states. The               has previously shown to be important in the sliding tile puz-
state-space is also undirected since applying the same ﬂip                zle (Korf 1985; Burns et al. 2012).
twice in a row merely undoes the effect of the original ﬂip.                 Observe that there are always at most two gap decreasing
   A state π  is said to be a neighbour of state π if there              moves in any state. This is because Mi can only resolve a
exists an action Mi such that Mi (π) = π  . We also use                  gap (if one exists) between locations i and i + 1 if π[1] is
h∗ (π) to denote the cost of the optimal solution path start-             adjacent to π[i+1] in πgoal , and this is only true if π[i+1] =
ing at π. A node n is given by a state, denoted by n.state,               π[1] + 1 or π[i + 1] = π[1] − 1. However, in many states
and a sequence of ﬂips, called a path, that leads to π from               there are no gap decreasing moves. These states are said to
πinit . The cost of this path is referred to by g(n). Node n             be locked. In such states, we can show the following:
is called a child of node n if there is an action Mi such that
                                                                          Lemma 2.1. There is at least one gap neutral action in any
n .state = Mi (n.state) and the path to n is given by the
                                                                          non-goal state that is locked.
path to n with the addition of action Mi .
   A heuristic function h is a function from the set of states               This holds because we can always replace one gap or ad-
to the set of non-negative real numbers. A heuristic function             jacency with another in such states. A complete proof can be
h is admissible if for every state π, h(π) ≤ h∗ (π). In an                found in a technical report (Valenzano and Yang 2017).
undirected unit-cost state-space, h is consistent if for every
pair of neighbouring states π and π  , |h(π) − h(π  )| ≤ 1. If                3    The Accuracy of the Gap Heuristic
admissible h, we also deﬁne the absolute heuristic error or               In this section, we demonstrate that while the gap heuristic is
AHE of h on state π as h∗ (π) − h(π).                                     very accurate on random permutations, it can be much more



                                                                    110
                     AHE of hG                                                      Heuristic Function
        N       0      1     2   3
                                          AHE          hG                 LD              LDD                2LD            2LDD
        16     369    581   49   1
                                            0     205, 330, 493     216, 267, 458     224, 031, 821      221, 584, 129   231, 096, 110
        20     335    621   44   0
                                            1     246, 800, 263     241, 319, 635     237, 261, 313      238, 902, 035   233, 210, 974
        24     332    642   26   0
                                            2      26, 213, 570      21, 050, 960      17, 482, 806       18, 289, 424    14, 566, 568
        28     338    647   15   0
                                            3          648, 977          360, 630          224, 202           224, 908        127, 456
        40     340    650   10   0
                                            4            8, 216            2, 906            1, 457             1, 103             491
        50     386    609   5    0
                                            5                80                10                 0                  0               0
        60     363    636   1    0
                                                          (b) AHE of different heuristics over all 12-pancake states.
      (a) AHE of hG on 1, 000 ran-
      dom permutations per N .

             Table 1: The number of states with different AHE values on random permutations and the 12-pancake puzzle.


inaccurate. We also formally and experimentally investigate               maximum at the largest value of j for which 2·j ≤  1811 ·N ,
the worst-case AHE of hG for any pancake problem size N .                                                                 9
                                                                          at which point the expression has a value of  11 · N .

3.1     Accuracy on Random Permutations
We begin by analyzing the accuracy of hG on random per-                       While Theorem 3.1 guarantees that the worst-case AHE
mutations, since this is the standard method for construct-               of hG grows linearly with N , there is still a discrepancy be-
ing pancake puzzle test sets. We generated and solved 1, 000              tween the upper and lower bounds provided. To better un-
random permutation for seven values of N ranging from 16                  derstand the actual worst-case AHE, we performed an ex-
to 60. For each tested N , Table 1a shows a count of the num-             haustive search on all states for N ≤ 12. These experiments
ber of the 1, 000 states with each AHE. No permutation had                showed that the worst-case AHE is exactly  N2 −1 for every
an AHE of more than 3. For all tested N , hG was perfect                  N ≤ 12. For larger values of N , we use a particular state,
for between 33% and 39% of the problems, and off by no                    denoted by F G2N , to provide lower bounds on the worst-case
more than one for between 95% and 99.9% of the problems.                  AHE. For an even N , F G2N = 2, 1, 4, 3, ..., N, N − 1. We
The standard deviation of the AHE also decreases as N in-                 have solved this problem, which has N/2 gaps, up to size 28.
creases, from 0.57 when N = 16 to 0.48 when N = 60.                       For every N ≤ 18, h∗ (F G2N ) = N − 1 and so the worst-
   While we never encountered a random permutation with                   case AHE of hG for any N where 13 ≤ N ≤ 19 is at least
an AHE of hG over 3, an exhaustive search of the 12-                       N2  − 1.1 For 20 ≤ N ≥ 28, this pattern does not hold, as
pancake puzzle shows that the AHE of hG can be higher.                    h∗ (F G2N ) < N − 1 in this range. However, our experiments
This can be seen in column two of Table 1b, which shows                   with F G2N does show that the worse-case AHE of hG is at
the number of states with each AHE value encountered. The                 least 8 for 20 ≤ N ≤ 23 and at least 9 for 24 ≤ N ≤ 28.
table shows that the AHE can get as high as 5 in the 12-                      We note that F G2N is based on a burnt pancake state often
pancake puzzle. However, states with an AHE of 3 or more                  denoted by −IN . This puzzle is a variant of the standard
are exceedingly rare, consisting of only 0.13% of states.                 pancake puzzle, in which each pancake p has an orienta-
                                                                          tion of either +p or −p, and a pancake’s orientation changes
3.2     Bounds on the Worst-Case AHE of hG                                when it is ﬂipped (Gates and Papadimitriou 1979). The burnt
Let us now consider just how inaccurate the gap heuristic                 pancake state −IN , which is given by −1, −2, ..., −N ,
can get, by providing bounds on the worst-case AHE.                       was conjectured to have the longest optimal solution cost of
                                                                          any N burnt pancake state (Cohen and Blum 1995), though
Theorem 3.1. The maximum AHE over all N -pancake                          this has been shown to be false (Heydari and Sudborough
                             1                            9
states is no smaller than  14 ·N  and no larger than  11 ·N .         1997). F G22N can be constructed from −IN by replacing
                                                                          each −i entry in −IN with two entries 2i + 1, 2i. How-
Proof. For the lower bound, recall that Heydari and Sudbor-               ever, the optimal cost for F G22N can be lower than for −IN .
ough (1997) identiﬁed a family of states, where the state of
size N has an optimal cost of at least  1514 · N . Since these
states have N gaps, they guarantee the existence of a state                  4    Generating Harder Pancake Problems
with an AHE of at least  15                    1
                            14 · N  − N =  14 · N .
   For the upper bound, let π be the N -pancake state with                We now identify three methods for generating states on
maximum AHE. By Chitturi et al.’s bound (2009) on the di-                 which hG usually has a higher AHE than it does on random
ameter of the the N -pancake puzzle, h∗ (π) ≤  18                        permutations. In doing so, we provide ways of constructing
                                                        11 · N .
Since Fischer and Ginzinger’s 2-approximation algorithm                   large problem sets that are difﬁcult when using hG .
(2005)always ﬁnds a solution in at most 2 · hG (π) moves,
h∗ (π) ≤ 2 · hG (π). As such, if hG (π) = j, then the AHE of                 1
                                                                               For odd-valued N , this follows since for any π, π ◦ N + 1
π is at most min(2 · j,  18
                          11 · N ) − j. This expression hits its         has the same optimal cost and number of gaps as π.




                                                                    111
4.1   Problem Generation Methods                                            known to have a high AHE. For example, consider two
We had two main objectives when developing new state gen-                   “hard” N -pancake puzzle states π and π  , where π = π  ,
eration methods. First, we wanted these methods to generate                 and let (π + N ) denote the sequence given by incrementing
states for which hG has a higher average AHE than typically                 each entry of π by N (i.e. (3, 1, 2 + 3) = 6, 4, 5). Then
seen with random permutations. Secondly, we wanted these                    four potentially difﬁcult pancake problems of size 2N are
methods to easily allow for the generation of large test sets               π◦(π+N  ), (π+N  )◦π, (π+N )◦π  , and π  ◦(π+N ). More
of any size. While Gates and Papadimitriou (1979), Heydari                  generally, given a set S of N -pancake states and a set S  of
and Sudborough (1997), and Rockicki (2004) have all man-                    N  pancake states, we can generate states of size N + N  by
ually constructed problems that are considered “hard,” to-                  sampling a state from each of S and S  , and using one of the
gether they represent only a handful of states for any given                four possible combinations of these two states.2 We call this
N . In contrast, our methods can be used to generate large                  method bootstrapping from seed sets S and S  .
test sets of states with higher AHE values, and are thus                       Below, we experiment with test sets for the 16, 20, 24,
more conducive to studies regarding how an algorithm’s be-                  and 28-pancake puzzles, each containing 1, 000 states. For
haviour scales with problem size, large-scale and system-                   the initial seed sets, we used exhaustive search to ﬁnd the 50
atic experimentation, or investigations that require separate               8-pancake states with the highest AHE values, breaking ties
training and test data. These methods are described below.                  in favour of higher optimal cost. We did the same to get a
                                                                            set of 50 12-pancake problems. We denote these sets as S8
Self-Inverses. A permutation π is said to be a self-inverse                 and S12 , respectively. To construct the 16-pancake test set,
permutation if for all i, π[i] = π D [i]. This is equivalent to             S8 was used for both seed sets. For the 20-pancake set, S8
requiring that for all i and j, if π[i] = j then π[j] = i.                  and S12 were used. We then built set S16 consisting of 50 of
Notice that this condition allows for an integer to be mapped               the 1, 000 16-pancake states generated using bootstrapping,
to itself (i.e. π[i] = i). For example, π = 1, 4, 3, 2 is a               using the same selection criteria as was used for S8 and S12 .
self-inverse state since 1 and 3 are mapped to themselves,                  The 24-pancake set was built using S16 and S8 as seed sets,
π[2] = 4, and π[4] = 2.                                                     while S12 and S16 were used for the 28-pancake test set.
   As shown below, self-inverse states typically have a                        We note that the 24-pancake test set could have also been
higher AHE of hG than random permutations. To generate a                    constructed using two copies of S12 as the seed sets. The de-
self-inverse state π of size N , we use the following iterative             cision to do otherwise was made arbitrarily, and was not re-
procedure. We begin with set S = {1, ..., N }. On each it-                  visited because the generated problems were already found
eration, there are two possibilities. With probability 0.5, we              to have a high AHE for hG . This highlights a weakness of
randomly select and remove two distinct elements e1 and e2                  the bootstrapping approach: many decisions need to be made
from S, and set π[e1 ] = e2 and π[e2 ] = e1 . Otherwise, we                 for any N and it can be difﬁcult to make them consistently
randomly select and remove a single element e from S and                    for different values of N , as is desirable when testing how
set π[e] = e. This process then continues until S is empty.                 techniques scale with N . However, it is still simple to build
Short Cycles. A subset of elements {e1 , ..., ek } is in a k-               large sets using this method, and as we will see, they will
cycle in permutation π with order e(1) , ..., e(k)  if for any j          contain the hardest problems of all those considered.
in 1 ≤ j ≤ k − 1, π[e(j) ] = e(j+1) , and π[e(k) ] = e(1) . A
                                                                            4.2   Difﬁculty of New Benchmarks
well-known fact from group theory is that any permutation
can be expressed as a set of disjoint cycles. For example,                  We evaluated the new problem generation methods by build-
6, 3, 5, 2, 4, 1 consists of a 2-cycle with order 1, 6 and a            ing 16 test sets, one for each combination of four pan-
4-cycle with order 2, 3, 5, 4.                                            cake sizes — 16, 20, 24, and 28 — and four problem gen-
   Our second state generation method focuses on problems                   eration methods, including the use of randomly generated
with cycles that satisfy two speciﬁc conditions that were                   permutations. Each test set contains 1, 000 problems. The
found to lead to problems with high AHE. Speciﬁcally, each                  benchmarks used and the state generators can be found at
cycle has a size of 4 or less, and each cycle consists of a set             http://bit.ly/2pGEEt0. Table 2 shows the average,
of consecutive integers, though these integers do not neces-                median, maximum, and standard deviation of the AHE of
sarily appear consecutively in the cycle order. For example,                hG over the states in these sets. The table shows that the new
state 2, 4, 1, 3, 5, 7, 8, 6 satisﬁes these conditions, since the         generation methods lead to higher AHE values than is seen
cycles in this state are 1, 2, 4, 3, 5, and 6, 7, 8.                  with random permutations, and that on these new test sets,
   To generate a permutation π of size N of this kind, we                   the average, median, and maximum AHE generally increase
begin by uniformly selecting the size of the ﬁrst cycle from                with N . Self-inverse states have the lowest average AHE of
1, 2, 3, or 4. If k is the value generated, this means that 1,              the new methods, while bootstrapping has the highest.
2, ..., k will appear in π as part of some k-cycle. If k =                     To evaluate how the increased AHE impacts runtime, we
1, then we set π[1] = 1. Otherwise, we generate a random                    ran IDA∗ using hG on all 16 test sets. The average num-
ordering e1 , ..., ek  of 1 to k. We then set π[e1 ] = e2 , ...,          ber of node generations for each combination of N and state
π[ek−1 ] = π[ek ], and π[k] = e1 , thus assigning the ﬁrst                  generation method is shown in Figure 1. Notice that the ver-
cycle. The remaining cycles are set analogously.                            tical axis is in log-scale. The ﬁgure shows that the new gen-
Bootstrapping. Our ﬁnal problem generation method in-                          2
                                                                                 If the two sampled states are the same, then there are only two
volves concatenating together smaller problems that are                     possible unique combinations.




                                                                      112
                                                                                    Problem Generation Method
                                              Random                        Self-Inverse                 Short Cycles                    Bootstrapping
                           N        Av       Med Max       SD       Av      Med Max        SD      Av    Med Max           SD      Av     Med Max         SD
                      16            0.68     1    3       0.57     1.59         2   5     0.79    2.12      2       5     1.06    3.69     4       6     0.85
                      20            0.72     1    2       0.54     1.71         2   4     0.79    2.69      3       6     1.16    4.99     5       7     0.87
                      24            0.69     1    2       0.51     1.79         2   5     0.78    3.21      3       7     1.21    5.59     6       8     0.83
                      28            0.68     1    2       0.50     1.87         2   5     0.80    3.63      4       7     1.18    6.61     7       9     0.86

Table 2: AHE of hG on 16 different test sets. The table shows the average (Av), median (Med), maximum (Max), and standard
deviation (SD) over the 1, 000 problems generated for each generation method and problem size (N ) considered.


                               1x1010                                                             h(π) =  and there is some neighbour π  of π such that
                                                                                                  h(π  ) < h(π). The exit distance of h from a state π is the
                                    9
                                1x10
    Average Node Generations




                                1x108                                                             minimum number of actions needed to reach an exit. Notice
                                1x107                                                             that this means that any exit has an exit distance of 0.
                                    6
                                1x10                                                                 Consecutive locations i, i + 1, ..., i + j in a permutation
                               100000                                                             π forms a strip of size j + 1 if there are no gaps between
                                10000                                                             the pancakes in those locations, and that sequence of loca-
                                 1000                                Random                       tions is maximal (i.e. on either side of the strip there is a gap
                                  100                            Self-Inverse
                                                                 Short Cycles                     or the end of the permutation). A strip of size 2 or more is
                                   10
                                                                Bootstrapping                     descending if π[i] > π[i + 1] > ... > π[i + j], and ascend-
                                    1
                                        16        20                  24            28            ing otherwise. Two strips from i to i + j and i to i + j 
                                                      Pancake Size (N)
                                                                                                  where i ≤ i + j < i ≤ i + j  are in order if the pan-
                                                                                                  cakes in the strip from i to j are smaller than the pancakes
Figure 1: IDA∗ scaling behaviour on different benchmarks.                                         in the strip from i to j  . The rightmost strip is the one end-
                                                                                                  ing at location N . For example, 1, 2, 3, 5, 4 has two strips:
                                                                                                  an ascending strip of size 3 from locations 1 to 3, and a de-
eration methods yield substantially harder problems for an                                        scending strip of size 2 from location 4 to 5. The latter strip
IDA∗ guided by hG than just randomly generating permuta-                                          is the rightmost and the two strips are in order.
tions. This is not due to an increase in average optimal cost,                                       We now deﬁne the following family of states:
as the opposite is true. For example, the average optimal cost                                    Deﬁnition 2. π is a Fischer-Ginzinger (FG) state if and
for random permutations when N = 28 is 26.8, while it                                             only if π has at least two strips, and all strips in π are de-
is 24.2, 21.1, and 21.4 for the self-inverse, short cycle, and                                    scending, have a size of at least two, and are in order.
bootstrapped states, respectively.
   These results show that the new generation methods can                                            For example, 3, 2, 1, 5, 4 is an FG state, while 1, 2, 4, 3
be used to construct pancake puzzle test tests on which the                                       and 2, 1, 3, 5, 4 are not FG states since they have an as-
gap heuristic is less accurate than on randomly generated                                         cending strip and strip of size 1, respectively. The F G2N
permutations. As such, these methods provide an alternative                                       states in Section 3.2 states are also FG states in which all
way to test how algorithms are affected by heuristic accuracy                                     strips have size 2. Notice that all FG states are locked.
in a domain with a high branching factor like the pancake                                            We can now characterize states according to their exit dis-
puzzle, other than purposefully degrading the heuristic as                                        tance. First, notice that for any state in which there is a gap
has been done in other work (Holte et al. 2016).                                                  decreasing move, the exit distance is 0. For locked states,
                                                                                                  consider the following corollary of Lemma 5 from Fischer
                                5       Topology of the Gap Heuristic                             and Ginzinger (2005):
In this section, we extend the work of Fischer and Ginzinger                                      Corollary 5.1. The exit distance of hG for any locked state
(2005) by classifying pancake states according to the size                                        that is not an FG state is 1.
of the plateaus around them. To simplify this analysis, we
                                                                                                     Fischer and Ginzinger proved this by providing appropri-
assume that in all states, there is gap between locations N
                                                                                                  ate sequences of actions that could decrease the number of
and N + 1. Doing so removes the postﬁx of a state if it is
                                                                                                  gaps for all possible cases of non-FG locked states. How-
already sorted, since this portion of the state will have no im-
                                                                                                  ever, their result does not characterize the exit distance of
pact on the number of gaps or the optimal solution cost. For
                                                                                                  FG states. To do so, we deﬁne an easy FG state as an FG
example, where π = 2, 1, 4, 3 and π  = 2, 1, 4, 3, 5, 6, 7,
                                                                                                  state with exactly 2 strips such that the rightmost strip has
clearly hG (π) = hG (π  ) and h∗ (π) = h∗ (π  ).
                                                                                                  a size of 2. The remaining FG states are called hard FG
   We begin with some additional notation. Following Hoff-
                                                                                                  states. We can now show the following:
mann (2005), a plateau for h is a connected set of one or
more states that all have the same heuristic value. An exit                                       Theorem 5.2. The exit distance of hG is 1 for any easy FG
from a plateau with heuristic value  is a state π such that                                      state and 2 for any hard FG state.



                                                                                            113
Proof Sketch. The proof of this statement can be found in                  6.2   Lock Detection
its entirety in a technical report (Valenzano and Yang 2017).              Let us now consider the estimates returned by a 1-step
The following is a sketch of this proof.                                   lookahead of hG on non-goal state π. Assume that Mi is
   If π is an easy FG state, it has the following form N −                the action that leads to the neighbour of π with the low-
2, ..., 1, N, N − 1. As such, π has two gaps, one of which                est heuristic value. By deﬁnition, this means that LG  1 (π) =
can be removed by applying MN −1 and then MN to reach                      hG (Mi (π)) + 1. If Mi is a gap decreasing move, this value
state π  = N − 1, N − 2, ..., 1, N .                                    will be hG (Mi (π)) + 1 = hG (π) − 1 + 1 = hG (π). If Mi
   If π is a hard FG state π, let  ≥ 2 be the size of the                 is not a gap decreasing move, then π must be locked. Since
rightmost strip. Then we can easily verify that the follow-                there is always a gap neutral move applicable in any non-
                                                                                                                  1 (π) = h (Mi (π)) +
ing action sequence removes a gap: MN , M , and then MN .                 goal locked state by Lemma 2.1, LG                G
Thus, the exit distance is no more than 2. We show that the                1 = h (π) + 1 in this case. Therefore, the value of LG
                                                                                  G
                                                                                                                                     1 (π)
exit distance is greater than 1 by contradiction. If it is 1, then         will be hG (π) + 1 if π is locked and hG (π) otherwise.
there exists a move Mi such that Mi (π) is not locked. Since                  As such, we can determine the value of LG   1 (π) with a lin-
π is an FG state, π is locked, and so Mi is either gap increas-            ear scan of π in search of the locations of pancakes π[1] + 1
ing or gap neutral. If it is gap increasing, the consistency of            and π[1] − 1. If there is a gap above either of these pancakes,
hG guarantees that the exit distance is at least 2. Otherwise,             then there is a gap decreasing move in π and the value of
Mi (π) can be shown to be locked in all cases, which is done               LG1 (π) is h (π). Otherwise, L1 (π) = h (π) + 1. We refer
                                                                                       G                    G         G
in the technical report. This contradiction ensures that the                                        G
                                                                           to this calculation of L1 as lock detection or LD.
exit distance of π cannot be 1.                                 
   The results above show that the exit distance of any pan-               LD as Early Checking. We note that LD is not entirely
cake state is at most 2. In fact, for any locked state, the ac-            new, as it can be viewed as a slight variant of an often
tions that lead to the nearest exit consist solely of gap neutral          used IDA∗ enhancement that we call early checking. This
moves. This means that the gap heuristic does not have any                 domain-speciﬁc enhancement for IDA∗ is applicable when
heuristic local minima, and every state π can be solved sub-               using heuristics like hG , for which we can incrementally cal-
optimally along a path that does not include a gap increasing              culate the heuristic value of a child state Mi (π) given π and
move. Such a solution can also be shown to be found by Fis-                hG (π), without actually generating Mi (π), . In such cases,
cher and Ginzinger’s two-approximation algorithm (2005).                   we can “check” if the f -cost of a node n is higher than the
                                                                           current IDA∗ threshold, and thereby prune n “early” without
   However, there are states that cannot be solved optimally
                                                                           generating it if its f (n) does exceed the threshold. This pre-
without using a gap increasing moves, which we veriﬁed ex-
                                                                           generation pruning is especially important in the pancake
perimentally using an IDA∗ instance that pruned such moves
                                                                           puzzle, where generating Mi (π) is O(N ).
and occasionally was found to return suboptimal solutions.
                                                                              When using hG , we refer to this method as gap early
                                                                           checking. Gap early checking will actually generate the ex-
         6    Enhancing the Gap Heuristic                                  act same set of nodes as LD, since neither will generate any
In this section, we use the local topology analysis from Sec-              neighbours of a locked state π if f (π) is equal to the current
tion 5 to develop several enhancements for the gap heuristic.              threshold. The main difference between gap early checking
                                                                           and LD is that LD aggressively checks each move to see
                                                                           if one is gap decreasing, while gap early checking does so
6.1   Heuristic Lookahead                                                  “lazily.” However, we can also construct an incremental ver-
We begin by deﬁning a d-step heuristic lookahead of                        sion of LD that allows us to compute LG     1 (Mi (π)) without
heuristic h on state π. Let us ﬁrst assume that no goal state              generating Mi (π), and thus perform LD early checking. The
can be reached from π along a path of no more than d ac-                   same will be true of the other enhancements discussed be-
tions. In that case, the optimal path from π to a goal state               low, though we omit the details for the sake of clarity.
must pass through one of the descendants of π at depth d.                     LD is also related to the EPEIDA∗ algorithm (Goldenberg
In a unit-cost domain, this means that the minimum value of                et al. 2014). Using hG with this IDA∗ variant essentially in-
d+h(π  ) seen over all descendants at depth d from π will be              volves using the incremental hG computation to deﬁne an
an admissible estimate of the cost to reach the goal from π.               operator selection function (OSF), which directly returns
We refer to this value as the d-step lookahead estimate for                the children of a node that satisfy the current IDA∗ thresh-
π. In the case that the goal state can be reached from π in                old. Both an IDA∗ using heuristic LD and an EPEIDA∗ us-
fewer than d steps, then the lookahead must return the cost                ing hG would examine the same set of nodes, and merely
of the shortest such path to ensure admissibility.                         differ in their formulation. That is, the increased pruning
   While the estimates provided by a d-step lookahead on                   seen with the LD formulation is the result of an improved
hG should be at least as accurate as hG alone, a naive im-                 heuristic, while the equivalent pruning in EPEIDA∗ is the
plementation of this technique would require the generation                result of using the OSF to perform partial node expansion.
of O((N − 1)d ) states at depth d. However, we will show
that due to the topology of the gap heuristic, we can efﬁ-                 6.3   Two-Level Lock Detection
ciently compute the lookahead of hG for depths of one and                  We now show that due to the topology of the pancake puz-
two. Note, we use LG 1 (π) and L2 (π) to denote the estimates              zle, we can also compute the estimate returned by a 2-step
                                 G

returned by a 1 and 2-step lookahead of hG on state π.                     lookahead of hG for any state π in linear time and without



                                                                     114
TwoLevelLockCheck(permutation π):                                       the gap decreasing move Mi currently being checked, and
 1: locked ← TRUE, move index i ← 2                                     the pancake p that would be on top of the stack in Mi (π).
 2: while (locked == TRUE) and i ≤ N do                                 LevelTwo scans π looking for the pancakes that should be
 3:    if |π[i + 1] − π[1]| == 1 and
                                                                        adjacent to p. When such a pancake π[] is found in line 9,
                |π[i + 1] − π[i]| = 1 then
 4:        locked ← LevelTwo(π, i, π[i])                                the function checks if there is a gap beside π[] in Mi (π) that
 5:    i←i+1                                                            can be removed. There are two possible cases to consider.3
 6: return locked                                                       If i > , then π[ + 1] would be on top of π[] in Mi (π). The
                                                                        algorithm therefore checks if there is a gap between π[] and
LevelTwo(π, move index i, pancake p):
                                                                        π[ + 1] (line 10). If i < , then π[ − 1] will be on top
 7: locked ← TRUE, location  ← 1                                       of π[] in Mi (π), so the function checks for a gap between
 8: while (locked == TRUE) and  ≤ N do
                                                                        those locations. If a gap is found, then there is a descendant
 9:    if |π[] − p| == 1 then
10:                                         1) or
           if (i >  and |π[] − π[ + 1]| =                            of π at depth 2 with a heuristic value hG (π) − 2 and so
                                                                        LG2 (π) = h (π) (line 11). Otherwise, we have to check the
                                                                                      G
                                                  1) then
                    (i <  and |π[] − π[ − 1]| =
11:            return FALSE                                             other possible gap decreasing actions.
12:    ←+1                                                               Because there are at most two gap decreasing moves in
13: return locked                                                       π, the linear scan of LevelTwo is only done at most twice.
                                                                        As such, LG  2 (π) can be computed in time linear in N if π is
Algorithm 1: Linear time check if all gap decreasing moves              not locked. Since the same is true for locked states as shown
                                                                                   2 (π) can always be computed without generating
in π lead to locked states.                                             above, LG
                                                                        the O(N 2 ) nodes needed to naively do the lookahead.
                                                                           We call the computation of LG   2 (π) by detecting and clas-
generating any neighbours of π. We do so by considering                 sifying locked states and using TwoLevelLockCheck for un-
different cases for π. If hG (π) = 1, it is easy to show that           locked states, as two-level lock detection or 2LD. Note that
there is a gap decreasing action in π and h∗ (π) = 1. There-            in our implementation, the detection and classiﬁcation of
fore, LG2 (π) = 1. As such, we now assume h (π) > 1.
                                                   G
                                                                        locked states is done concurrently with the top-level scan
Without loss of generality we also assume that there is a gap           in TwoLevelLockCheck.
between locations N and N + 1 of π, as in Section 5.
   Let us start with the case that π is locked. If π is a hard          6.4      Using the Dual State
FG state, then the minimum heuristic value of any state at              We now consider two ways for improving performance
depth 2 from π is hG (π) by Theorem 5.2. As such, LG   2 (π) =          when using LD or 2LD that exploit a state’s dual. While
hG (π) + 2. Otherwise, π is an easy FG state or an non-FG               maintaining the dual state during the search will mean that
locked state. In these cases, Corollary 5.1 and 5.2 guarantee           applying each action takes twice as long, the improvements
that LG2 (π) = h (π) + 1.
                 G
                                                                        in heuristic accuracy will overcome this extra cost.
   Now recall that we showed that locks could be detected                  Zahavi et al. (2008) showed that for any state π, h∗ (π) =
with a linear time scan in the previous section. FG detection             ∗ D
                                                                        h (π ). If h is an admissible heuristic, this means that
and classiﬁcation can also clearly be done during this scan,            max(h(π), h(π D )) is an admissible — and potentially more
simply by keeping track of the size, number, and orientation            accurate — heuristic estimate for π. Unfortunately, this tech-
of the encountered strips. As such, we can detect a lock and            nique does not improve hG , since hG (π) = hG (π D ) for any
compute LG  2 (π) in time linear in N whenever π is locked.             π, because inverting a state preserves adjacencies. In partic-
   Let us now show that we can also compute LG        2 (π) ef-         ular, if there is an adjacency between pancakes p1 and p2
ﬁciently when π is not locked. If π is not locked and either            which are in locations j and j + 1 of π, then |p1 − p2 | = 1.
gap decreasing move leads to another state that is not locked,          As such, there is an adjacency between pancakes j and j + 1
then there is a state at depth 2 with a heuristic value of              in π D since they are in consecutive locations p1 and p2 .
hG (π) − 2. As such, LG  2 (π) = h (π). If all gap decreasing
                                    G
                                                                           However, a lookahead of hG can return a different value
moves in π lead to locked states, then LG 2 (π) = h (π) + 1.
                                                     G
                                                                        for π and π D . For example, π = 2, 3, 1, 5, 4 has a gap de-
This holds because if Mi is a gap decreasing move and                   creasing move M2 , while π D = 3, 1, 2, 5, 4 is locked. As
Mi (π) is locked, then there is a gap neutral move in Mi (π)            such, we can further improve heuristic accuracy by taking
by Lemma 2.1, and so some neighbour of Mi (π) must also                 the maximum of either LD or 2LD over π and π D . We refer
have a heuristic value of hG (Mi (π)) = hG (π) − 1.                     to the resulting techniques as LDD and 2LDD .
   Computing LG  2 (π) when π is not locked, thus merely re-               The dual of a state π can also be used to check if π is
quires us to identify if there is a gap decreasing move in π            locked in constant time. To see this, recall that a gap de-
that does not lead to a locked state. Algorithm 1 provides a            creasing move in π must resolve a gap above either π[1] + 1
linear time method for this purpose. The algorithm begins               or π[1] − 1. Moreover, the location of π[1] + 1 in π is given
with a call to TwoLevelLockCheck, which scans π in search               immediately by π D [π[1] + 1]. Finding and checking for the
of index i such that Mi is a gap decreasing move in π. When             ﬁrst gap decreasing move can now be done by checking for a
such a move is found in line 3, a second function, LevelTwo,            gap between locations π D [π[1] + 1] and π D [π[1] + 1] − 1. If
is called to check if Mi leads to a locked state. Of note, Lev-         π[1] > 1, ﬁnding and checking for a gap above π[1] − 1 can
elTwo does this in linear time and without generating Mi (π).
   The parameters given to LevelTwo are π, the index i of                  3
                                                                                = i since otherwise p = π[], which contradicts line 9.




                                                                  115
                                                                                                         4
then done similarly. Since the dual of π D is π, we can also




                                                                        Factor of Runtime Improvement
                                                                                                                LD
use an analogous approach to check if π D is locked. Thus,                                              3.5    LDD




                                                                            Over the Gap Heuristic
                                                                                                               2LD
LDD can be performed in constant time.                                                                        2LDD
   The above process can also be extended to perform the                                                 3
TwoLevelLockCheck component of 2LDD on both π and π D                                                   2.5
in constant time. This leaves FG detection and classiﬁcation
as the only linear time component of 2LDD .                                                              2

                                                                                                        1.5
6.5   Accuracy of the Enhanced Heuristics
                                                                                                         1
Let us now consider how these enhancements impact heuris-                                                     16           20               24   28
tic accuracy on all 12! states in the 12-pancake puzzle. Ta-                                                                Pancake Size (N)
ble 1b show counts of the number of states with each pos-
sible AHE value when using the standard hG heuristic, and            Figure 2: Runtime improvement when using hG enhance-
then when adding these enhancements. The table shows that            ments over hG alone on problems with short cycles.
LD, LDD , 2LD, and 2LDD improved the heuristic values
of 6.1%, 10.3%, 9.2%, and 14.1%, respectively, of all states
on which hG was not already perfect. The enhancements are            runtime improvement over hG when using each enhance-
particularly effective when hG is more inaccurate. For ex-           ment over different values of N . In contrast, the improve-
ample, on states for which hG has an AHE of 3 or higher,             ment generally stays similar on the states generated from
heuristics LD, LDD , 2LD, and 2LDD improved the heuristic            bootstrapping. For example, these problems take an average
values of 45.5%, 66.7%, 66.7%, and 81.7%, respectively.              of 12.85 minutes each to solve when using IDA∗ with hG
                                                                     and early checking when N = 28. 2LDD generated 11.6
7     Evaluation of the Heuristic Enhancements                       times fewer nodesthan hG , and the runtime improved by a
In this section, we experiment with the hG enhancements              factor of 4.5. These values are similar to the improvements
on the 16 test sets deﬁned in Section 4.2 which range over           shown in Table 3 that were seen when using 2LDD on the
four different values for N and the four different problem           24-pancake states generated with bootstrapping.
generation methods. All experiments were performed using
an IDA∗ enhanced by early checking (see Section 6.2) on a                                                             8   Related Work
machine with a Intel Xeon W3550 3.07GHz processor and                Bouzy (2015) evaluated Monte Carlo search methods for
8 MB of cache. The C++ code for these experiments can be             suboptimally solving standard and burnt pancake problems.
found at http://bit.ly/2pGEEt0.                                      One enhancement considered was a depth-limited search on
   We begin by considering the performance of IDA∗ on the            just the gap decreasing moves, which was used to detect if
24-pancake puzzle. The average number of nodes generated             applying a given action in a given state would lead to only
and the runtime in seconds on each 24-pancake puzzle test            locked states within some horizon. While this technique is
set is shown in Table 3. For each metric, the relative im-           related to a d-step heuristic lookahead, it was not used to
provement made when using each enhancement over using                improve admissible heuristic estimates as we do.
just hG is shown in parentheses. For example, the bottom-               A depth-ﬁrst lookahead was used by Stern et al. (2010) to
right entry of the table shows that using 2LDD improved              improve memory efﬁciency in an A∗ search. This lookahead
runtime by a factor of 5.4 over hG .                                 examined and pruned states according to f -cost instead of
   The table shows that the enhancements substantially de-           by depth. It was also a domain-independent technique and
crease the number of nodes generated, even on random per-            thus had to generate all relevant descendant states.
mutations where hG is already quite accurate. The relative              Felner et al. (2010) also considered a 1-step lookahead in
improvement increases as the average AHE of hG increases,            the pancake puzzle as part of a bi-directional search. How-
with the largest improvement seen on the bootstrapped                ever, their lookahead required the generation of all children
states. However, runtime does not improve as much as node            and was done in the context of a pattern database heuristic.
generations. For example, on the bootstrapped states, 2LDD              Several works have analyzed the accuracy and local
generates 9.8 times fewer nodes while runtime decreases by           search topology of different panning heuristics. Examples
a factor of 5.4. This occurs because the enhancements in-            include the local search topology analysis of the delete re-
crease the per-node time needed to compute heuristic values.         laxation heuristic by Hoffmann (2005), and a comparison of
   Table 3 also shows that LDD and 2LD lead to similar               admissible heuristics by Helmert and Mattmüller (2008).
gains. However, the improvements seen when using looka-
head and a state’s dual appear to be quite complementary,                                               9          Conclusion and Future Work
given how much further improvement is seen with 2LDD .               In this work, we have shown that the gap heuristic is gen-
   The impact on both node generations and time seen when            erally very accurate on a large percentage of problems, and
using the heuristic enhancements appears to remain rela-             thus rarely underestimates the optimal cost of any state by
tively constant as N increases. One exception is with states         more than two. However, it is more inaccurate on certain
with short cycles, on which the impact of 2LDD increases             problems and we have shown that this worst-case inaccu-
with N . This is seen in Figure 2, which shows the average           racy grows with the puzzle size. We then identiﬁed methods



                                                               116
                                                           Problem Generation Method
                        Random                   Self-Inverse                 Short Cycles                         Bootstrapping
 Heuristic      Nodes            Time         Nodes          Time          Nodes           Time                  Nodes           Time
 hG          2, 323(1.0)    0.0009(1.0)    57, 361(1.0)    0.021(1.0)      2, 361, 650(1.0)   0.84(1.0)    42, 037, 553(1.0)    28.0(1.0)
 LD          1, 756(1.3)    0.0008(1.1)    39, 610(1.4)    0.017(1.2)      1, 339, 064(1.8)   0.60(1.4)    18, 894, 828(2.2)    15.4(1.8)
 LDD         1, 278(1.8)    0.0006(1.5)    28, 539(2.0)    0.013(1.6)         847, 500(2.8)   0.39(2.2)    10, 069, 646(4.2)     8.3(3.4)
 2LD         1, 381(1.7)    0.0007(1.3)    28, 289(2.0)    0.015(1.4)         824, 297(2.9)   0.45(1.9)     9, 347, 059(4.5)     9.4(3.0)
 2LDD           898(2.6)    0.0005(1.8)    18, 293(3.1)    0.011(1.9)         434, 467(5.4)   0.27(3.1)     4, 308, 345(9.8)     5.2(5.4)

Table 3: Performance of the enhancements on different 24-pancake benchmarks. Values shown are the average over 1, 000 test
problems. Time is in seconds. The factor of that each enhancement improves over hG for each metric is shown in parentheses.


for easily generating large sets of problems that can be used             Fischer, J., and Ginzinger, S. W. 2005. A 2-Approximation Algo-
to test how search algorithms behave on those pancake prob-               rithm for Sorting by Preﬁx Reversals. In Proceedings of the 13th
lems with more heuristic error.                                           Annual European Symposium (ESA), 415–425.
   We also analyzed the local search topology of the gap                  Gates, W., and Papadimitriou, C. 1979. Bounds for sorting by
heuristic, and classiﬁed all states in terms of the size of               preﬁx reversal. Discrete Math 27:47–57.
the plateaus around them. This classiﬁcation was then used                Goldenberg, M.; Felner, A.; Stern, R.; Sharon, G.; Sturtevant,
as the basis of several gap heuristic enhancements that ef-               N. R.; Holte, R. C.; and Schaeffer, J. 2014. Enhanced Partial
ﬁciently calculate a heuristic lookahead and also exploit a               Expansion A*. Journal of Artiﬁcial Intelligence Research 50:141–
state’s dual in order to improve heuristic accuracy. These en-            187.
hancements were also shown to lead to substantial speedups.               Hayes, B. 2007. Sorting out the genome. American Scientist
   In recent work, it has been shown that the use of bi-                  95:386–391.
directional search and partial node expansions can outper-                Helmert, M., and Mattmüller, R. 2008. Accuracy of admissible
form IDA∗ on the pancake puzzle (Lippi, Ernandes, and Fel-                heuristic functions in selected planning domains. In Proceedings
ner 2016). Given that our enhancements strictly improve on                of the Twenty-Third AAAI Conference on Artiﬁcial Intelligence,,
the gap heuristic and that the relative impact of the extra per-          938–943.
node cost of using the enhancements should decrease in that               Helmert, M. 2010. Landmark Heuristics for the Pancake Problem.
setting, we would expect to see similar trends. However, we               In Proceedings of the Third Annual Symposium on Combinatorial
leave such an investigation as future work.                               Search.
                                                                          Heydari, M. H., and Sudborough, I. H. 1997. On the Diameter of
                   Acknowledgements                                       the Pancake Network. Journal of Algorithms 25(1):67–94.
We thank Sheila McIlraith and the Knowledge Representa-                   Hoffmann, J. 2005. Where ‘Ignoring Delete Lists’ Works: Local
                                                                          Search Topology in Planning Benchmarks. Journal of Artiﬁcial
tion group at the University of Toronto for their support on
                                                                          Intelligence Research 24:685–758.
this work. We also thank the anonymous reviewers for their
comments, particularly in connecting the work with existing               Holte, R. C.; Felner, A.; Sharon, G.; and Sturtevant, N. R. 2016.
                                                                          Bidirectional search that is guaranteed to meet in the middle. In
research and helping to make Lemma 2.1 properly precise.                  Proceedings of the Thirtieth AAAI Conference on Artiﬁcial Intel-
                                                                          ligence, 3411–3417.
                         References                                       Korf, R. E. 1985. Depth-First Iterative-Deepening: An Optimal
Bouzy, B. 2015. An Experimental Investigation on the Pancake              Admissible Tree Search. Artiﬁcial Intelligence 27(1):97–109.
Problem. In Proceedings of the Fourth Workshop on Computer
                                                                          Lippi, M.; Ernandes, M.; and Felner, A. 2016. Optimally solv-
Games(CGW) and the Fourth Workshop on General Intelligence
                                                                          ing permutation sorting problems with efﬁcient partial expansion
in Game-Playing Agents, (GIGA), 30–43.
                                                                          bidirectional heuristic search. AI Communications 29(4):513–536.
Bulteau, L.; Fertin, G.; and Rusu, I. 2015. Pancake Flipping is
                                                                          Qiu, K.; Meijer, H.; and Akl, S. G. 1991. Parallel Routing and
hard. Journal of Computer and System Sciences 81(8):1556–1574.
                                                                          Sorting of the Pancake Network. In Proceedings of the Interna-
Burns, E. A.; Hatem, M.; Leighton, M. J.; and Ruml, W. 2012.              tional Conference on Computing and Information, 360–371.
Implementing Fast Heuristic Search Code. In Proceedings of the
                                                                          Rockicki, T.              2004.        Tom’s Pancake Entry.
Fifth Annual Symposium on Combinatorial Search.
                                                                          http://tomas.rokicki.com/pancake/.
Chitturi, B.; Fahle, W.; Meng, Z.; Morales, L.; Shields, C.; Sud-         Stern, R.; Kulberis, T.; Felner, A.; and Holte, R. 2010. Using
borough, I. H.; and Voit, W. 2009. An (18/11)n upper bound                Lookaheads with Optimal Best-First Search. In Proceedings of
for sorting by preﬁx reversals. Theoretical Computer Science              the Twenty-Fourth AAAI Conference on Artiﬁcial Intelligence.
410(36):3372–3390.
                                                                          Valenzano, R. A., and Yang, D. 2017. A Formal Characterization
Cohen, D. S., and Blum, M. 1995. On the Problem of Sorting                of the Local Search Topology of the Gap Heuristic. CoRR.
Burnt Pancakes. Discrete Applied Mathematics 61(2):105–120.
                                                                          Zahavi, U.; Felner, A.; Holte, R. C.; and Schaeffer, J. 2008. Du-
Felner, A.; Moldenhauer, C.; Sturtevant, N. R.; and Schaeffer, J.         ality in permutation state spaces and the dual search algorithm.
2010. Single-Frontier Bidirectional Search. In Proceedings of the         Artiﬁcial Intelligence 172(4-5):514–540.
Twenty-Fourth AAAI Conference on Artiﬁcial Intelligence, 59–64.




                                                                    117
