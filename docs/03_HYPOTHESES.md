# Гипотезы и план скрещиваний

Одна тема — одна гипотеза/направление. Результаты фиксировать в `04_RESULTS.md`. Для удобства агентов у каждой гипотезы есть **ID**, **статус**, краткое **обоснование** и **источник**.

---

## Сводка гипотез (ID → статус)

| ID | Кратко | Статус | Обоснование (1 строка) | Источник |
|----|--------|--------|------------------------|----------|
| H1 | Рефакторинг, тесты, без скрещивания | не проверена | Чистый код = надёжная база для экспериментов | проект |
| H2 | Блокнот → beam | не проверена | notebook даёт хорошее начальное решение, beam его улучшает | проект |
| H3 | Блокнот + 91584 пайплайн | не проверена | единый пайплайн упрощает A/B-сравнения и комбинирование | проект |
| H4 | Блокнот + beam + 91584 (+ML) | не проверена | трёхуровневая стратегия: notebook → beam → ML-beam | проект |
| H_merge | merge notebook + beam | не проверена | min по двум сабмитам строго не хуже лучшего из них | проект |
| H_grid | грид по beam-параметрам | не проверена | текущие 128×128, alpha=0, w=0.5 подобраны не оптимально | проект |
| H_per_n | выбор метода по n | не проверена | оптимальный алгоритм зависит от размера n | проект; Rokicki |
| H_notebook_treshold | подбор treshold для v4/v3_* | не проверена | treshold=2.6 — не глобальный оптимум | проект |
| H_crossing_selective | selective crossing only для «длинных» id | не проверена | selective crossing снижает память при сохранении качества | проект |
| H_heuristic | alpha>0, mix_h, другие эвристики | не проверена | gap_h точен на случайных стеках, но слаб на hard-задачах | проект; Valenzano & Yang 2017; Rokicki |
| H_ml | ML-beam (91584) как улучшатель | не проверена | ML-beam из 91584 показывал выигрыш на части задач | 91584-baseline |
| H_ensemble_multi_run | несколько конфигов + merge | не проверена | дисперсия качества между конфигами → выигрыш при merge | проект |
| H_RL_policy | чистая RL-политика лучше baseline | **провалена** | RL(BC) = 165967, baseline = 158680; rollout слабее жадного | проект |
| H_RL_imitation_then_finetune | BC + PG улучшает baseline | частично | BC-этап провален; PG-этап не запускался | проект |
| H_RL_value_for_small_beam | V(s) для малого beam | требует проверки | малый beam + обученная V может дать компромисс качество/память | проект |
| H_RL_Q | Q(s,a) вместо политики | требует проверки | argmax Q(s,a) — один rollout без beam | проект |
| **H_LD** | LD/2LD lookahead улучшает gap_h | не проверена | lock detection за O(N), доказано снижает AHE и узлы IDA* | **Valenzano & Yang 2017** |
| **H_LDD** | LDD/2LDD (dual state) ещё точнее | не проверена | max(LD(π), LD(π^D)) улучшает оценку без дополнительного поиска | **Valenzano & Yang 2017** |
| **H_hard_bench** | hard benchmarks (SI, SC, Bootstrap) как тест | не проверена | на случайных стеках gap_h почти идеален; hard-стеки реалистичны | **Valenzano & Yang 2017; Rokicki** |
| **H_singletons** | singletons как tie-breaking в beam | не проверена | Rokicki: «почти весь выигрыш — от singletons»; O(1) overhead | **Rokicki** |
| **H_incremental** | инкрементальное представление стека | не проверена | ~3 операции на flip вместо O(N); нужно при bottleneck скорости | **Rokicki** |
| **H_two_ended** | двунаправленный поиск | не проверена | одновременно от start и goal сокращает глубину поиска вдвое | **Rokicki** |
| **H_MCS** | Monte Carlo Search с rollout-политиками | не проверена | Bouzy: MCS уровня 3–4 даёт ~1.04 аппрокс. против ~1.22 у жадного | **Bouzy 2015** |

\\* — статус всегда относится к **текущим экспериментам** (см. `runs/experiment_results.jsonl` и `04_RESULTS.md`). При новых данных статус нужно обновлять.

**Важно:** в оригиналах скоры 89980 и 91584 достигнуты **без** скрещивания: блокнот даёт 89980 только солвером v4 (без beam), 91584 — только baseline+beam (без блокнота). Скрещивание «блокнот + beam» (H2–H4) — это эксперимент поверх двух независимых подходов.

---

## H1: Улучшение без скрещивания

**Статус:** не проверена.

**Гипотеза:** Рефакторинг, модульность, тесты и единый контракт (формат перестановок/ходов) сами по себе повысят поддерживаемость и надёжность без изменения алгоритмов.

**Действия:** Разбить код на модули, добавить unit- и интеграционные тесты, убрать дублирование (например, два разных `parse_permutation`), унифицировать представление ходов (list[int] vs list[str] "Rk").

---

## H2: Копия блокнота + Beam search

**Статус:** не проверена.

**Гипотеза:** Использование beam search (из 91584) как пост-обработки для решений, полученных солверами блокнота (например v3_1, v3_5), даст более короткие решения при сохранении корректности.

**Действия:**
- Взять baseline_moves_fn = солвер из блокнота (возвращающий list[int] ходов).
- Вызывать `beam_improve_or_baseline_h` с этим baseline.
- Замерить: доля улучшений, средний gain, время; сравнить с baseline = классический pancake sort.

---

## H3: Копия блокнота + pancake_91584 (без ML)

**Статус:** не проверена.

**Гипотеза:** Объединение утилит и пайплайнов из обоих файлов (общий парсинг, форматы, оценка, best_solution, run_grid) позволит комбинировать солверы блокнота и beam search 91584 в одном конвейере и упростит A/B сравнения.

**Действия:**
- Единый модуль core (parse, apply_moves, moves_to_str, moves_len).
- Солверы блокнота и beam в одном интерфейсе (функция perm -> list[int]).
- Общий слой submission (best_solution, evaluate vs baseline, сохранение CSV).

---

## H4: Блокнот + Beam search + pancake_91584 (включая ML)

**Статус:** не проверена.

**Гипотеза:** Трёхуровневая стратегия даст лучший результат: (1) быстрый солвер блокнота или классический baseline; (2) улучшение beam search с эвристикой; (3) опционально улучшение beam+ML для подмножества задач (например, большие n). Все компоненты в одном репозитории с общими тестами и метриками.

**Действия:**
- Реализовать стратегию выбора: по n или по времени выбирать цепочку [notebook/baseline] -> [beam] -> [optional ML-beam].
- Сравнить суммарную длину решений и время против только beam и только блокнота.
- Фиксировать конфигурации (beam_width, depth, пороги блокнота) в конфиге и в `04_RESULTS.md`.

---

## План и гипотезы по сильному улучшению скора

Контекст: целевые скоры — блокнот v4 → 89980, baseline+beam 128×128 → 91584; baseline ~158680. Crossing-режимы ограничены max_n и памятью. Консоль не анализировалась (нет доступа к выводу прогонов); опора — все md и код.

### План (порядок работ без кода — только план)

1. **Зафиксировать бейзлайны** — один прогон `run_best_score.py --mode notebook`, один `--mode beam`, сохранить submission в `runs/notebook.csv` и `runs/beam.csv`, посчитать score через `submission_stats.py` или `evaluate`. Убедиться, что воспроизводим 89980 и 91584.
2. **Merge нескольких сабмитов** — запустить 2–3 метода (notebook, beam, при возможности crossing на части id), объединить через best_solution (min score по каждому id). Замерить суммарный score. Это быстрый выигрыш без изменения алгоритмов.
3. **Грид по параметрам beam** — на подмножестве теста (например `select_cases_per_n` по n_list с k=3–5) прогнать `run_grid` по alpha, w, beam_width, depth. Выбрать top_cfgs по mean gain, затем `full_eval_top_cfgs` на полном тесте. Сравнить с текущими 128×128, alpha=0, w=0.5.
4. **Стратегия по n** — разбить id по n (малое / среднее / большое). Для малого n опционально notebook или notebook+beam; для большого — только beam (или baseline+beam) из-за памяти. Реализовать в main/run_best_score выбор метода по n (или по id-диапазону, если n коррелирует с id).
5. **Notebook: порог и солвер** — варьировать treshold для v4 (2.6 — из оригинала) и пробовать v3_1/v3_5 с разными порогами; для части строк брать min по длине из нескольких солверов. Опционально добавить солверы из блокнота (v3_3, v3_6 и т.д., см. 07_AUDIT_GAPS).
6. **Crossing без max_n** — чтобы не обрезать по max_n: либо запускать notebook+beam только для id с n ≤ N0 (например 50), остальные — чистый beam; либо один проход notebook для всех (дешёво), второй проход beam с baseline=notebook только для id, где длина решения выше порога (например медиана по n). Так ограничиваем память, но используем notebook как baseline там, где это выгодно.
7. **Эвристика и beam** — попробовать alpha>0 (mix_h), другие веса w; при наличии времени — портировать ML-beam из 91584 и использовать для подмножества (например большие n).

### Гипотезы (для сильного улучшения)

- **H_merge**  
  Объединение нескольких сабмитов через best_solution (минимум по длине решения на каждый id) даёт выигрыш по суммарному score без изменения солверов. Ожидание: notebook сильнее на части id, beam на другой части; merge даёт строго не хуже лучшего из двух и может дать заметный выигрыш.

- **H_grid**  
  Текущие параметры beam (128×128, alpha=0, w=0.5) не оптимальны по всему тесту. Систематический грид (run_grid + full_eval_top_cfgs) найдёт конфигурацию с меньшим суммарным числом ходов. Возможны разные конфиги для разных диапазонов n.

- **H_per_n**  
  Оптимальный метод зависит от n: для малых n эвристический поиск блокнота (или notebook+beam) даёт короче; для больших n beam от baseline или notebook+beam с ограничением памяти выгоднее. Явная диспетчеризация по n улучшит общий score при фиксированном бюджете времени/памяти.

- **H_notebook_treshold**  
  Порог treshold=2.6 для v4 подобран в оригинале не глобально оптимально. Перебор treshold (и при необходимости других солверов v3_1/v3_5) по подвыборке с замером score позволит поднять качество «чистого» блокнота и любого пайплайна, где блокнот — базовый солвер.

- **H_crossing_selective**  
  Полный crossing (notebook+beam) на всех строках упирается в память. Селективный crossing: notebook для всех строк; beam с baseline=notebook только для id, где длина решения выше квантиля по n (или выше медианы). Остальные id — оставить решение блокнота. Это снижает среднюю длину там, где beam даёт максимальный выигрыш, без взрыва памяти.

- **H_heuristic**  
  Замена или дополнение gap_h (alpha=0): mix_h (alpha>0) или другие эвристики могут дать лучшую навигацию beam и меньшую длину решений. Проверка через run_grid по alpha и w.  
  *Связь с литературой:* Valenzano & Yang 2017 показывают, что gap_h очень точен на случайных задачах, но сильно ошибается на hard-задачах (Self-Inverse, Short Cycles, Bootstrapping). Rokicki: tie-breaking по singletons — отдельный сильный эффект.

- **H_ml**  
  Перенос ML-beam из 91584 в src/ml и использование для подмножества задач (например большие n) может дополнительно снизить число ходов там, где эвристический beam выходит на потолок. Зависит от наличия моделей и времени на инференс.

- **H_ensemble_multi_run**  
  Запуск нескольких конфигураций (например 2–3 набора beam params или notebook+beam с разными treshold/beam_width) и merge по min length per id даёт выигрыш за счёт дисперсии качества между конфигами. Трудозатраты растут линейно от числа прогонов.

Итог: сначала реализовать merge двух сабмитов (notebook + beam) и замерить score; затем грид по beam и селективный crossing; при необходимости — тонкая настройка по n и порогам блокнота. Результаты фиксировать в `04_RESULTS.md`.

---

### Облегчение памяти и времени (без RL)

Текущие узкие места: beam 128×128 + словарь best_g дают большой расход памяти; notebook search (permute_search) при больших n тоже; crossing удваивает нагрузку (сначала notebook, потом beam).

- **Уменьшить beam**: фиксировать beam_width/depth меньше (например 32×48 или 64×64), принять небольшой проигрыш по качеству в обмен на память и скорость. Грид по малым конфигам.
- **Notebook-only для больших n**: при n > N0 не вызывать beam, только baseline или только блокнот (v4 с лимитом max_states). Так избегаем взрыва памяти на больших перестановках.
- **Merge без пересчёта**: два прогона — только notebook и только beam — сохранить в CSV; merge по min length. Не запускать crossing (notebook_then_beam) вообще — экономим память и время, выигрыш за счёт объединения двух дешёвых сабмитов.
- **Селективный beam**: один раз пройтись только блокнотом (или только baseline), записать длину решения по каждому id; второй проход — beam с baseline=notebook только для id, где длина выше порога (например 90-й перцентиль по n). Остальные id не трогать. Число вызовов beam сильно падает → меньше времени и пиковой памяти.
- **Один метод по умолчанию**: если цель — стабильно уложиться в память, зафиксировать один лёгкий метод (например только notebook v4 или только beam 32×48) и не комбинировать на лету.

---

### RL (reinforcement learning)

Текущий ML в 91584 — **регрессия V(s)** (расстояние до цели), данные с графа Кэли (random walks + BFS), инференс — beam с ML-эвристикой. Память и время на инференсе по-прежнему определяются beam.

**Зачем RL:** при инференсе по **политике** π(a|s) или по **жадному Q(s,a)** мы делаем один rollout до решения: на каждый шаг один forward по сети, без beam. Память O(1) по числу состояний, время O(длина_решения) × forward. Это радикально легче, чем beam 128×128.

**MDP:** состояние s = перестановка (длина n), действия a = k ∈ {2,…,n} (разворот префикса Rk), переход детерминированный, награда r = -1 за шаг (или 0 в терминале). Цель — максимизировать сумму наград = минимизировать число шагов.

**Варианты:**

- **H_RL_policy**  
  Обучить политику π(a|s). Инференс: жадный rollout до identity. Гипотеза: после сходимости длина траекторий будет не хуже baseline. **Статус: провалена** — BC-политика (165863) хуже baseline (158680) на 7183 шага.

- **H_RL_value_for_small_beam**  
  Обучить V(s) через RL (TD-style). Использовать V как эвристику в малом beam (width 4–8, depth 16–32). Гипотеза: малый beam + обученная V даёт компромисс качество/память лучше, чем большой beam + gap_h.

- **H_RL_imitation_then_finetune**  
  BC + fine-tune через PPO/policy gradient. Гипотеза: имитация даёт разумный старт, RL сокращает число шагов. **Статус: частично** — BC-этап провален; PG-этап не запускался.

- **H_RL_Q**  
  DQN/Q-learning: Q(s,a) с дискретными действиями k. Инференс: argmax_a Q(s,a). Те же плюсы по памяти/времени.

**Итог по данным прогонов 2026-02-25 (runs/experiment_results.jsonl):**
- Прогон #1: score(RL)=165967, gain_vs_baseline=−7287, improved=153, worse=847.
- Прогон #2: score(RL)=165863, gain_vs_baseline=−7183, improved=163, worse=818.

- **H_RL_policy** — **провалена**: даже лучший из двух прогонов (165863) хуже baseline (158680) на 7183 шага; улучшения есть только на части кейсов, в сумме RL проигрывает.
- **H_RL_imitation_then_finetune** — **частично**: стадия BC даёт политику хуже baseline; этап PG (fine-tune) не запускался, поэтому утверждение «RL сокращает число шагов» ещё не проверялось. Имеет смысл прогнать с `--pg-epochs` и сравнить снова.
- **H_RL_value_for_small_beam**, **H_RL_Q** — **требуют проверки** (не запускались).

---

### Новые гипотезы из исследовательских статей

#### H_LD: Lock Detection как улучшение gap_h
**Статус:** не проверена.  
**Источник:** Valenzano & Yang, SoCS 2017 (`docs/13_BASELINE_PAPER_2.md`).

**Гипотеза:** Добавление 1-шагового lookahead LD к gap_h (lock detection: проверить, есть ли ход, уменьшающий gap; если нет — increment h на 1) даст более точную admissible heuristic за O(N) дополнительных операций. Применительно к нашему beam search: LD-оценки лучше приоритизируют кандидатов в beam, что сокращает число ходов в решениях.

**Что доказано в статье:** LD и 2LD существенно снижают AHE и число узлов IDA* на всех бенчмарках, включая Self-Inverse, Short Cycles, Bootstrapping. Вычислимы за O(N) (без явного порождения потомков).

**Как проверить:** реализовать `ld_h(perm)` и `2ld_h(perm)` в `src/heuristics/h_functions.py`; добавить в `make_h`; прогнать `run_grid` с этой эвристикой на тестовой выборке; сравнить скор с чистым `gap_h` (baseline = 91584).

---

#### H_LDD: Dual-state (LDD/2LDD) для ещё более точных оценок
**Статус:** не проверена.  
**Источник:** Valenzano & Yang, SoCS 2017 (`docs/13_BASELINE_PAPER_2.md`).

**Гипотеза:** Вычисление `max(LD(π), LD(π^D))` (где π^D — dual перестановка) даёт строго более точные нижние оценки, чем LD(π) в одиночку. При beam search: поддерживать π^D совместно с π (overhead — обновление dual на каждый ход) и использовать LDD как heuristic. Дополнительная точность → меньше узлов → короче решения.

**Замечание:** dual перестановка уже упоминается в теории (Rokicki, Valenzano & Yang). Для нашей задачи (pancake puzzle, не burnt) h_G(π) = h_G(π^D) по самой h_G, но LD/2LD могут давать разные значения для π и π^D — именно это используется в LDD/2LDD.

**Как проверить:** аналогично H_LD, но добавить расчёт dual и `max(ld_h(π), ld_h(π^D))` в beam.

---

#### H_hard_bench: Тяжёлые бенчмарки для честного тестирования эвристик
**Статус:** не проверена.  
**Источник:** Valenzano & Yang 2017 (`docs/13_BASELINE_PAPER_2.md`); Rokicki (`docs/09_TOMAS_ALG.md`).

**Гипотеза:** Текущий тестовый набор (`baseline/sample_submission.csv`, 2405 строк) скорее всего близок к случайным перестановкам, на которых gap_h ведёт себя почти идеально (AHE ≈ 0–1). Если в наборе присутствуют «тяжёлые» id (self-inverse, short cycles, арифметические прогрессии), они формируют узкое место. Генерация таких бенчмарков позволит:
- измерить AHE наших эвристик честно;
- проверить, где beam+gap_h уступает beam+LD;
- стресс-тестировать RL и MCS.

**Как проверить:** реализовать генераторы `gen_self_inverse(n)`, `gen_short_cycles(n)`, `gen_arithmetic(n, a, b)`, `gen_bootstrap(n)` в `src/heuristics/hard_bench.py`; прогнать все солверы; сравнить скоры.

---

#### H_singletons: Singleton-приоритет в beam как tie-breaking
**Статус:** не проверена.  
**Источник:** Tom Rokicki (`docs/09_TOMAS_ALG.md`).

**Гипотеза:** Rokicki атрибутирует «почти весь выигрыш» hash-based BFS сингулярному правилу: при коллизии по числу break'ов — оставить состояние с **большим числом singletons** (блинчиков, с обеих сторон которых разрыв). Применительно к нашему beam: при равном значении gap_h среди кандидатов beam выбирать те, у которых больше singletons. Это O(N) дополнительная операция на кандидата.

**Как проверить:** реализовать `count_singletons(perm)` в `h_functions.py`; добавить secondary sort в `beam_improve_or_baseline_h` (при равном h — предпочесть больший singletons); прогнать полный тест, сравнить скор.

---

#### H_incremental: Инкрементальное представление стека для ускорения
**Статус:** не проверена (низкий приоритет до упора в CPU).  
**Источник:** Tom Rokicki (`docs/09_TOMAS_ALG.md`).

**Гипотеза:** Текущая реализация флипов — срез и реверс списка Python (O(k) операций явно). Rokicki: двусвязный список через сумму соседей (`b[i] = prev + next`) позволяет делать flip за ~3 операции + инкрементальный hash. При миллионах вызовов в beam на большом тесте это может дать существенное ускорение.

**Когда имеет смысл:** только если профилирование покажет, что `apply_move_copy` / `beam_improve_or_baseline_h` — bottleneck. До этого — не реализовывать.

---

#### H_two_ended: Двунаправленный поиск
**Статус:** не проверена.  
**Источник:** Tom Rokicki (`docs/09_TOMAS_ALG.md`).

**Гипотеза:** Rokicki запускает поиск одновременно от начального состояния (forward) и от целевого (backward, inverse). Встреча в середине сокращает глубину поиска вдвое при той же памяти. Применительно к нашему beam: параллельный beam forward + backward с проверкой пересечения. Сложнее в реализации, но потенциально сильно сокращает длину решений для больших n.

**Как проверить:** реализовать bidirectional beam в `src/heuristics/beam_bi.py`; сравнить скор с однонаправленным beam на подвыборке.

---

#### H_MCS: Monte Carlo Search с rollout-политиками
**Статус:** не проверена.  
**Источник:** Bouzy, CGW 2015 (`docs/10_BOUZY_PAPER.md`).

**Гипотеза:** Bouzy показывает, что MCS уровня 3–4 с доменно-зависимыми rollout-симуляторами (EffSort, AltSort, BREF) даёт ~1.04 аппроксимацию диаметра против ~1.22 у жадного baseline. Для нашего проекта: использовать наши notebook-солверы или baseline как rollout-политики внутри nested MCS. На каждом шаге выполнять несколько rollout до конца, выбирать ход с лучшим средним результатом по длине. Полиномиальная сложность по числу симуляций × уровень вложенности.

**Как проверить:** реализовать `mcs_solve(perm, rollout_fn, num_simulations, depth)` в `src/heuristics/mcs.py`; прогнать на подвыборке; сравнить скор и время с beam. Ключевой параметр — rollout_fn: можно пробовать `pancake_sort_moves` (baseline), notebook v4, RL-политику.

---

*По мере проведения экспериментов добавлять сюда уточнения гипотез и ссылки на 04_RESULTS.md. После прогонов — анализировать данные по инструкции в docs/08_ANALYSIS.md и дописывать по каждой гипотезе итог: подтверждена / провалена / частично / требует проверки (с обоснованием по данным из runs/experiment_results.jsonl и 04_RESULTS).*
